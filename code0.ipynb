{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests.packages.urllib3\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import urllib.request\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# code\n",
    "header = {\"User_Agent\":\"組員電腦的\"}\n",
    "letter_list = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\",\n",
    "               \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\",\n",
    "               \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "img_list = []\n",
    "height_list = []\n",
    "web_list = []\n",
    "name_list = []\n",
    "\n",
    "for i in letter_list:\n",
    "    for num in range(1,37):\n",
    "        web = f\"https://celebsheight.org/celebrities-starting-with-{i}-heights?page={num}\"\n",
    "        page = requests.get(web, headers = header)\n",
    "        soup =  BeautifulSoup(page.content, \"html.parser\")\n",
    "        img_links = soup.find_all(\"img\", {\"src\": re.compile('.*?\\.jpg')})\n",
    "        for link in img_links:\n",
    "            img_list.append(link[\"src\"])\n",
    "for i in letter_list:\n",
    "    for num in range(1,37):\n",
    "        web= f\"https://celebsheight.org/celebrities-starting-with-{i}-heights?page={num}\"\n",
    "        web_list.append(web)\n",
    "for web in web_list:\n",
    "    page1 = requests.get(web, headers = headers)\n",
    "    soup1 =  BeautifulSoup(page1.content, \"html.parser\")\n",
    "    height = soup1.find_all(\"div\", class_ = \"celeb-grid-item-n\")\n",
    "    each_height = []\n",
    "    each_name =[]\n",
    "    for i in height:\n",
    "        each_height.append(i.find(\"h2\").text)\n",
    "        each_name.append(i.find(\"h1\").text)\n",
    "    height_list.append(each_height)\n",
    "    name_list.append(each_name)\n",
    "    \n",
    "height_lists = []\n",
    "name_lists = []\n",
    "\n",
    "for i in range(len(height_list)):\n",
    "    for a in range(len(height_list[i])):\n",
    "        height_split = height_list[i][a]\n",
    "        name_height = height_split.split(\" \")\n",
    "        height = name_height[-2]\n",
    "        height_lists.append(height)\n",
    "for i in range(len(name_list)):\n",
    "    for a in range(len(name_list[i])):\n",
    "        name = name_list[i][a]\n",
    "        name_lists.append(name)\n",
    "\n",
    "folder_path =\"組員的電腦路徑\"\n",
    "if os.path.exists(folder_path) == False:\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for index, item in enumerate(img_list):\n",
    "    if item:\n",
    "        try:\n",
    "            html = requests.get(item, verify = False)\n",
    "            img_name = folder_path + height_lists[index] + \"-\" + name_lists[index] + '.png'\n",
    "            with open(img_name, 'wb') as file:\n",
    "                file.write(html.content)\n",
    "                file.flush()\n",
    "            file.close()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
